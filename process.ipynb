{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class SongId(Enum):\n",
    "    Keaton  = 1\n",
    "    Alyse   = 2\n",
    "    Morty   = 3\n",
    "    Jay     = 4\n",
    "    Richard = 5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sensor(Enum):\n",
    "    AF3 = 0\n",
    "    F7 = 1\n",
    "    F3 = 2\n",
    "    FC5 = 3\n",
    "    T7 = 4\n",
    "    P7 = 5\n",
    "    O1 = 6\n",
    "    O2 = 7\n",
    "    P8 = 8\n",
    "    T8 = 9\n",
    "    FC6 = 10\n",
    "    F4 = 11\n",
    "    F8 = 12\n",
    "    AF4 = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the global settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_dir         = \"../tf_alpha/\"\n",
    "beta_dir          = \"../tf_beta/\"\n",
    "user              = \"Richard\"\n",
    "points_per_sample = 100\n",
    "\n",
    "alpha_sensors = [\"F4\",  \"F7\",  \"F8\"]\n",
    "beta_sensors  = [\"AF3\", \"AF4\", \"FC5\", \"F4\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha Files Found: 100\n",
      "Beta Files Found: 100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "alpha_files = os.listdir(alpha_dir)\n",
    "beta_files  = os.listdir(beta_dir)\n",
    "print(\"Alpha Files Found: %d\" % len(alpha_files))\n",
    "print(\"Beta Files Found: %d\" % len(beta_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all files that aren't a reading of the users song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_of_user_song(filename):\n",
    "    song_id = filename.split('_')[1]\n",
    "    \n",
    "    if song_id == 's':\n",
    "        return False\n",
    "    \n",
    "    return int(song_id) == SongId[user].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_all_songs_from_other_users(file_list):\n",
    "    i = 0\n",
    "    while i < len(file_list):\n",
    "        if reading_of_user_song(file_list[i]):\n",
    "            i += 1\n",
    "        else:\n",
    "            file_list.pop(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha files with user song found: 16\n",
      "Beta file with user song found: 16\n"
     ]
    }
   ],
   "source": [
    "remove_all_songs_from_other_users(alpha_files)\n",
    "remove_all_songs_from_other_users(beta_files)\n",
    "print(\"Alpha files with user song found: %d\" % len(alpha_files))\n",
    "print(\"Beta file with user song found: %d\" % len(beta_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the files into authorized and attack sets\n",
    "\n",
    "Authorized: The user is listening to their chosen song\n",
    "Attack:     Someone else listening to the user's song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_auth(filename):\n",
    "    return filename.split('_')[0] == user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_auth = []\n",
    "beta_auth  = []\n",
    "alpha_att  = []\n",
    "beta_att   = []\n",
    "\n",
    "for f in alpha_files:\n",
    "    #print(\"{}: {}\".format(f, is_auth(f)))\n",
    "    if is_auth(f):\n",
    "        alpha_auth.append(f)\n",
    "    else:\n",
    "        alpha_att.append(f)\n",
    "        \n",
    "for f in beta_files:\n",
    "    #print(\"{}: {}\".format(f, is_auth(f)))\n",
    "    if is_auth(f):\n",
    "        beta_auth.append(f)\n",
    "    else:\n",
    "        beta_att.append(f)\n",
    "        \n",
    "# print(alpha_auth)\n",
    "# print(alpha_att)\n",
    "# print(beta_auth)\n",
    "# print(beta_att)\n",
    "\n",
    "del alpha_files\n",
    "del beta_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beginning reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statistics as stats\n",
    "def get_avgs(l, n):\n",
    "    \"\"\"\n",
    "    return a list of averages using each set of n\n",
    "    elements in order from n\n",
    "    \"\"\"\n",
    "    \n",
    "    i = 0\n",
    "    avgs = []\n",
    "    while i + n < len(l):\n",
    "        avgs.append(stats.mean(l[i:i+n]))\n",
    "        i += n\n",
    "    \n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create containers for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha_tag = \"_ALPHA\"\n",
    "beta_tag  = \"_BETA\"\n",
    "\n",
    "auth_data = dict()\n",
    "att_data  = dict()\n",
    "\n",
    "for sensor in alpha_sensors:\n",
    "    auth_data[sensor + alpha_tag] = []\n",
    "    att_data[sensor + alpha_tag]  = []\n",
    "    \n",
    "for sensor in beta_sensors:\n",
    "    auth_data[sensor + beta_tag] = []\n",
    "    att_data[sensor + beta_tag]  = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and process data from authorized user files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in alpha_auth:\n",
    "    df = pd.read_csv(alpha_dir + f)\n",
    "    for sensor in alpha_sensors:\n",
    "        key = sensor + alpha_tag\n",
    "        auth_data[key] += get_avgs(df[key].values, points_per_sample)        \n",
    "        \n",
    "for f in beta_auth:\n",
    "    df = pd.read_csv(beta_dir + f)\n",
    "    for sensor in beta_sensors:\n",
    "        key = sensor + beta_tag\n",
    "        auth_data[key] += get_avgs(df[key].values, points_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F4_ALPHA: 64\n",
      "F7_ALPHA: 64\n",
      "F8_ALPHA: 64\n",
      "AF3_BETA: 64\n",
      "AF4_BETA: 64\n",
      "FC5_BETA: 64\n",
      "F4_BETA: 64\n"
     ]
    }
   ],
   "source": [
    "for key in auth_data.keys():\n",
    "    print(\"{}: {}\".format(key, len(auth_data[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in and process data from attacker files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in alpha_att:\n",
    "    df = pd.read_csv(alpha_dir + f)\n",
    "    for sensor in alpha_sensors:\n",
    "        key = sensor + alpha_tag\n",
    "        att_data[key] += get_avgs(df[key].values, points_per_sample)        \n",
    "        \n",
    "for f in beta_att:\n",
    "    df = pd.read_csv(beta_dir + f)\n",
    "    for sensor in beta_sensors:\n",
    "        key = sensor + beta_tag\n",
    "        att_data[key] += get_avgs(df[key].values, points_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F4_ALPHA: 192\n",
      "F7_ALPHA: 192\n",
      "F8_ALPHA: 192\n",
      "AF3_BETA: 192\n",
      "AF4_BETA: 192\n",
      "FC5_BETA: 192\n",
      "F4_BETA: 192\n"
     ]
    }
   ],
   "source": [
    "for key in auth_data.keys():\n",
    "    print(\"{}: {}\".format(key, len(att_data[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-c5bf4e0ef332>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-c5bf4e0ef332>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Print to File\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Print to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth_df = pd.DataFrame(auth_data)\n",
    "auth_df.to_csv(\"auth.csv\")\n",
    "\n",
    "att_df  = pd.DataFrame(att_data)\n",
    "att_df.to_csv(\"att.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
